{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DnDMeOAUYVfh",
        "nHdZ4MG9YY2q"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdvCelIOrt72"
      },
      "source": [
        "# StyleGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this notebook is to better understand StyleGAN and enable generation of video by interpelating within a latent space.\n",
        "\n",
        "The most recent version of this notebook was developed by Josh Urban Davis (https://joshurbandavis.com/, @joshurbandavis). See my GitHub repository for pre-trained models or my fine-tuning notebook for methods to modify pre-trained models."
      ],
      "metadata": {
        "id": "lxd4Tut3uCtW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpQY6Z0ScLhu",
        "outputId": "d1f4c421-061c-4e67-d914-f2e25375b2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan.git\n",
        "%cd stylegan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Total 77 (delta 0), reused 0 (delta 0), pack-reused 77\u001b[K\n",
            "Unpacking objects: 100% (77/77), done.\n",
            "/content/stylegan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBYV1EBmeaiC",
        "outputId": "cbb19156-2fde-46d5-abf3-f6863544d72d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "\n",
        "tflib.init_tf()\n",
        "\n",
        "# Load pre-trained network.\n",
        "url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'\n",
        "with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
        "    _G, _D, Gs = pickle.load(f)\n",
        "    # _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.\n",
        "    # _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.\n",
        "    # Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0703 00:26:18.898688 140519557355392 deprecation_wrapper.py:119] From /content/stylegan/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "W0703 00:26:18.901242 140519557355392 deprecation_wrapper.py:119] From /content/stylegan/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0703 00:26:18.902614 140519557355392 deprecation_wrapper.py:119] From /content/stylegan/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0703 00:26:18.919707 140519557355392 deprecation_wrapper.py:119] From /content/stylegan/dnnlib/tflib/tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0703 00:26:18.920955 140519557355392 deprecation_wrapper.py:119] From /content/stylegan/dnnlib/tflib/tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ .... done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0703 00:26:30.908653 140519557355392 deprecation.py:323] From <string>:364: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aoosLxiOM7c"
      },
      "source": [
        "**The section below allows for downloading of model data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHgs_7ytJxXE"
      },
      "source": [
        "# This section used for generating images and downloading them locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8hd4x_e81Qs"
      },
      "source": [
        "mkdir generated_faces_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5rjaCcT9IEu"
      },
      "source": [
        "# Pick latent vector.\n",
        "rnd = np.random.RandomState(100)\n",
        "latents = rnd.randn(1, Gs.input_shape[1])\n",
        "\n",
        "# Generate image.\n",
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB8fxNggBIcw",
        "outputId": "be99952d-ff3d-4bcc-c32b-941b02d308c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import scipy.misc\n",
        "\n",
        "\n",
        "root_dir = '/content/stylegan/generated_faces_test/'\n",
        "\n",
        "\n",
        "for num_pics in range(1000,1100):\n",
        "  # Pick latent vector.\n",
        "  rnd = np.random.RandomState(num_pics)\n",
        "  latents = rnd.randn(1, Gs.input_shape[1])\n",
        "\n",
        "  fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "  images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n",
        "\n",
        "  for i, images in enumerate(images):\n",
        "    filename = '%sframe_%05d.png'%(root_dir, num_pics+1)\n",
        "    scipy.misc.imsave(filename, images)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK2rvV3j9kLC"
      },
      "source": [
        "from google.colab import files\n",
        "!zip -r generated_faces_1.zip generated_faces\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFhgyFx9HHFX"
      },
      "source": [
        "files.download('generated_faces_1.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4nTRnuBIvAT"
      },
      "source": [
        "# This section generates images and saves them directly to gogle drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqwwHl_OGbvi",
        "outputId": "ba71f427-34e9-4801-ddbb-a9136e97fdf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3oAlX4mHEXR",
        "outputId": "78d1cabe-6081-4793-fe5e-1acd61360cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "import scipy.misc\n",
        "\n",
        "root_dir = '/content/gdrive/My Drive/generatedFaces/'\n",
        "\n",
        "for num_pics in range(9025,15000):\n",
        "  # Pick latent vector.\n",
        "  rnd = np.random.RandomState(num_pics)\n",
        "  latents = rnd.randn(1, Gs.input_shape[1])\n",
        "\n",
        "  fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "  images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n",
        "\n",
        "  for i, images in enumerate(images):\n",
        "    filename = '%sframe_%05d.png'%(root_dir, num_pics+1)\n",
        "    scipy.misc.imsave(filename, images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2cfb3b5ec1ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%sframe_%05d.png'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_pics\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'scipy.misc' has no attribute 'imsave'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfrtvNVzLudi"
      },
      "source": [
        "# **Below is mostly a reference for the above code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxwNGoO_LtcG"
      },
      "source": [
        "import scipy.misc\n",
        "\n",
        "root_dir = '/content/stylegan/generated_faces/'\n",
        "for i, images in enumerate(images):\n",
        "    filename = '%sframe_%05d.png'%(root_dir, i+1)\n",
        "    scipy.misc.imsave(filename, images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDua3TmKJ3fw"
      },
      "source": [
        "# Random interpolation grid\n",
        "\n",
        "Based on the ProGAN interpolation code\n",
        "https://github.com/tkarras/progressive_growing_of_gans/blob/master/misc.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaaThUoYJ6Zn"
      },
      "source": [
        "import scipy\n",
        "\n",
        "grid_size = [2,2]\n",
        "image_shrink = 1\n",
        "image_zoom = 1\n",
        "duration_sec = 10.0\n",
        "smoothing_sec = 1.0\n",
        "mp4_fps = 60\n",
        "mp4_codec = 'libx264'\n",
        "mp4_bitrate = '16M'\n",
        "random_seed = 404\n",
        "mp4_file = 'random_grid_%s.mp4' % random_seed\n",
        "minibatch_size = 8\n",
        "\n",
        "num_frames = int(np.rint(duration_sec * mp4_fps))\n",
        "random_state = np.random.RandomState(random_seed)\n",
        "\n",
        "# Generate latent vectors\n",
        "shape = [num_frames, np.prod(grid_size)] + Gs.input_shape[1:] # [frame, image, channel, component]\n",
        "all_latents = random_state.randn(*shape).astype(np.float32)\n",
        "all_latents = scipy.ndimage.gaussian_filter(all_latents, [smoothing_sec * mp4_fps] + [0] * len(Gs.input_shape), mode='wrap')\n",
        "all_latents /= np.sqrt(np.mean(np.square(all_latents)))\n",
        "\n",
        "\n",
        "def create_image_grid(images, grid_size=None):\n",
        "    assert images.ndim == 3 or images.ndim == 4\n",
        "    num, img_h, img_w, channels = images.shape\n",
        "\n",
        "    if grid_size is not None:\n",
        "        grid_w, grid_h = tuple(grid_size)\n",
        "    else:\n",
        "        grid_w = max(int(np.ceil(np.sqrt(num))), 1)\n",
        "        grid_h = max((num - 1) // grid_w + 1, 1)\n",
        "\n",
        "    grid = np.zeros([grid_h * img_h, grid_w * img_w, channels], dtype=images.dtype)\n",
        "    for idx in range(num):\n",
        "        x = (idx % grid_w) * img_w\n",
        "        y = (idx // grid_w) * img_h\n",
        "        grid[y : y + img_h, x : x + img_w] = images[idx]\n",
        "    return grid\n",
        "\n",
        "# Frame generation func for moviepy.\n",
        "def make_frame(t):\n",
        "    frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n",
        "    latents = all_latents[frame_idx]\n",
        "    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    images = Gs.run(latents, None, truncation_psi=0.7,\n",
        "                          randomize_noise=False, output_transform=fmt)\n",
        "\n",
        "    grid = create_image_grid(images, grid_size)\n",
        "    if image_zoom > 1:\n",
        "        grid = scipy.ndimage.zoom(grid, [image_zoom, image_zoom, 1], order=0)\n",
        "    if grid.shape[2] == 1:\n",
        "        grid = grid.repeat(3, 2) # grayscale => RGB\n",
        "    return grid\n",
        "\n",
        "# Generate video.\n",
        "import moviepy.editor\n",
        "video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n",
        "video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph4lh-eZ8Hw8"
      },
      "source": [
        "\n",
        "\n",
        "# Style mixing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvrdJmhZYcY-"
      },
      "source": [
        "## Coarse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uim75G44jgpK"
      },
      "source": [
        "import scipy\n",
        "\n",
        "duration_sec = 30.0\n",
        "smoothing_sec = 1.0\n",
        "mp4_fps = 40\n",
        "\n",
        "num_frames = int(np.rint(duration_sec * mp4_fps))\n",
        "random_seed = 500\n",
        "random_state = np.random.RandomState(random_seed)\n",
        "\n",
        "\n",
        "w = 512\n",
        "h = 512\n",
        "#src_seeds = [601]\n",
        "dst_seeds = [700]\n",
        "style_ranges = ([0] * 7 + [range(8,16)]) * len(dst_seeds)\n",
        "\n",
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "synthesis_kwargs = dict(output_transform=fmt, truncation_psi=0.7, minibatch_size=8)\n",
        "\n",
        "shape = [num_frames] + Gs.input_shape[1:] # [frame, image, channel, component]\n",
        "src_latents = random_state.randn(*shape).astype(np.float32)\n",
        "src_latents = scipy.ndimage.gaussian_filter(src_latents,\n",
        "                                            smoothing_sec * mp4_fps,\n",
        "                                            mode='wrap')\n",
        "src_latents /= np.sqrt(np.mean(np.square(src_latents)))\n",
        "\n",
        "dst_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in dst_seeds)\n",
        "\n",
        "\n",
        "src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\n",
        "dst_dlatents = Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\n",
        "src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "dst_images = Gs.components.synthesis.run(dst_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "\n",
        "\n",
        "canvas = PIL.Image.new('RGB', (w * (len(dst_seeds) + 1), h * 2), 'white')\n",
        "\n",
        "for col, dst_image in enumerate(list(dst_images)):\n",
        "    canvas.paste(PIL.Image.fromarray(dst_image, 'RGB'), ((col + 1) * h, 0))\n",
        "\n",
        "def make_frame(t):\n",
        "    frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n",
        "    src_image = src_images[frame_idx]\n",
        "    canvas.paste(PIL.Image.fromarray(src_image, 'RGB'), (0, h))\n",
        "\n",
        "    for col, dst_image in enumerate(list(dst_images)):\n",
        "        col_dlatents = np.stack([dst_dlatents[col]])\n",
        "        col_dlatents[:, style_ranges[col]] = src_dlatents[frame_idx, style_ranges[col]]\n",
        "        col_images = Gs.components.synthesis.run(col_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "        for row, image in enumerate(list(col_images)):\n",
        "            canvas.paste(PIL.Image.fromarray(image, 'RGB'), ((col + 1) * h, (row + 1) * w))\n",
        "    return np.array(canvas)\n",
        "\n",
        "# Generate video.\n",
        "import moviepy.editor\n",
        "mp4_file = '/tmp/output.mp4'\n",
        "mp4_codec = 'libx264'\n",
        "mp4_bitrate = '16M'\n",
        "\n",
        "video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n",
        "video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so7RMb9enS7j"
      },
      "source": [
        "## Fine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSd4uh4jpi0W"
      },
      "source": [
        "import scipy\n",
        "\n",
        "duration_sec = 20.0\n",
        "smoothing_sec = 1.0\n",
        "mp4_fps = 30\n",
        "\n",
        "num_frames = int(np.rint(duration_sec * mp4_fps))\n",
        "random_seed = 503\n",
        "random_state = np.random.RandomState(random_seed)\n",
        "\n",
        "\n",
        "w = 512\n",
        "h = 512\n",
        "style_ranges = [range(6,16)]\n",
        "\n",
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "synthesis_kwargs = dict(output_transform=fmt, truncation_psi=0.7, minibatch_size=8)\n",
        "\n",
        "shape = [num_frames] + Gs.input_shape[1:] # [frame, image, channel, component]\n",
        "src_latents = random_state.randn(*shape).astype(np.float32)\n",
        "src_latents = scipy.ndimage.gaussian_filter(src_latents,\n",
        "                                            smoothing_sec * mp4_fps,\n",
        "                                            mode='wrap')\n",
        "src_latents /= np.sqrt(np.mean(np.square(src_latents)))\n",
        "\n",
        "dst_latents = np.stack([random_state.randn(Gs.input_shape[1])])\n",
        "\n",
        "\n",
        "src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\n",
        "dst_dlatents = Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\n",
        "\n",
        "\n",
        "def make_frame(t):\n",
        "    frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n",
        "    col_dlatents = np.stack([dst_dlatents[0]])\n",
        "    col_dlatents[:, style_ranges[0]] = src_dlatents[frame_idx, style_ranges[0]]\n",
        "    col_images = Gs.components.synthesis.run(col_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "    return col_images[0]\n",
        "\n",
        "# Generate video.\n",
        "import moviepy.editor\n",
        "mp4_file = 'fine_%s.mp4' % (random_seed)\n",
        "mp4_codec = 'libx264'\n",
        "mp4_bitrate = '16M'\n",
        "\n",
        "video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n",
        "video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}